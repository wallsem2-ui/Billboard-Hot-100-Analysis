---
title: "Final Exam"
output: html_document
date: "2025-12-09"
author: "Ella Walls"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Part 1
My dataset is from the Billboard Hot 100 Number Ones Database, found on TidyTuesday in Github. The data covers every number one song from August 4, 1958 to January 11, 2025. My analysis looks at the number one songs from 2000-2025. 

Predictor Variables:
- Length of song (length_sec) - length of the song in seconds

- Year (date) - year taken from the date variable, date of the first week the song hit number one

- BPM (bpm) - beats per minute, taken from Spotify

- Overall rating (overall_rating) - mean of three rating scores from expert judges, 1-10 scale

- Happiness (happiness) - happiness measure on 0-100 scale, taken from Spotify


Response Variable:
Weeks at Number One (weeks_at_number_one) - total number of weeks the song held the number one spot, includes consecutive and nonconsecutive weeks

Other Variables:

- Song

- Artist

```{r Part 1}
library(tidyverse)
library(jsonlite)
library(dplyr)
library(ggplot2)
library(lubridate)
library(mplot)
library(caret)
library(rpart)  
library(rpart.plot)    
library(rsample)  
library(randomForest)
library(Metrics)  
library(tibble)
library(patchwork)

billboard <- readr::read_csv("https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-08-26/billboard.csv")
class(billboard$date)

billboard <- billboard %>%
  mutate(year = year(billboard$date))%>%
  filter(year>1999)%>%
  select(c(song, artist, year, weeks_at_number_one, overall_rating, length_sec, bpm, happiness))%>%
  mutate(song = unlist(song))%>%
  drop_na(weeks_at_number_one, length_sec, bpm, overall_rating)

nrow(billboard)
ncol(billboard)
head(billboard)
summary(billboard)
```

## Part 2
```{r Part 2}
#PLOT 1
longest <- billboard %>%
  filter(length_sec == max(length_sec, na.rm = TRUE))
mostweeks <- billboard %>%
  filter(weeks_at_number_one == max(weeks_at_number_one, na.rm = TRUE))
p1 <- ggplot(billboard)+
  geom_point(aes(x=length_sec, y=weeks_at_number_one), alpha=.7)+
  geom_smooth(data=billboard %>% filter(length_sec<500), aes(x = length_sec, y = weeks_at_number_one), method = "loess", se = TRUE, color = "navy") +
  geom_point(data=longest, aes(x=length_sec, y=weeks_at_number_one), color="darkorange3")+
  annotate("text", x = 584, y = 2, label = "All Too Well (10 Minute Version) \n Taylor Swift", color = "darkorange3", size = 2.5)+
  geom_point(data=mostweeks, aes(x=length_sec, y=weeks_at_number_one), color="purple2")+
  annotate("text", x = 130, y = 18, label = "Old Town Road \n Lil Nas X", color = "purple2", size = 2.5)+
  annotate("text", x = 230, y = 19, label = "A Bar Song (Tipsy)-Shaboozey", color = "purple2", size = 2.5)+
  labs(title="Weeks at Number One by Length of Song", x="Length (in seconds)", y="Weeks at Number One")+
  theme_minimal()

#PLOT 2
best.bpm.weeks <- billboard %>%
  filter(bpm>200)%>%
  filter(weeks_at_number_one>15)
p2 <- ggplot(billboard)+
  geom_point(aes(x=bpm, y=weeks_at_number_one), alpha=.7)+
  geom_smooth(aes(x = bpm, y = weeks_at_number_one), method = "loess", se = TRUE, color = "navy")+
  geom_point(data=best.bpm.weeks, aes(x=bpm, y=weeks_at_number_one), color="darkorange3")+
  annotate("text", x = 197, y = 13.6, label = "Last Night - Morgan Wallen \n Song with highest BPM that \n spent over 15 weeks at #1", color = "darkorange3", size = 2.5)+
  geom_point(aes(x=mean(bpm), y=0), color="purple2")+
  annotate("text", x = 120, y = -1, label = "Average BPM", color = "purple2", size = 2.5)+
  labs(title="Weeks at Number One by Song's BPM", subtitle="Song's BPM (beats per minute) found in Spotify data", x="BPM", y="Weeks at Number One")+
  theme_minimal()

#PLOT 3
happiest <- billboard %>%
  filter(happiness>97)
p3 <- ggplot(billboard)+
  geom_point(aes(x=happiness, y=weeks_at_number_one))+
  geom_smooth(aes(x = happiness, y = weeks_at_number_one), method = "loess", se = TRUE, color = "lightblue4")+
  geom_point(data=happiest, aes(x=happiness, y=weeks_at_number_one), color="darkorange3")+
    annotate("text", x = 100, y = 3.5, label = "Happiest Song:\nFamily Affair-\nMary J. Blige", color = "darkorange3", size = 2.5)+
  geom_point(aes(x=mean(happiness), y=0), color="goldenrod")+
  annotate("text", x = 55, y = -1, label = "Average Happiness", color = "goldenrod", size = 2.5)+
  labs(title="Weeks at Number One by Song Happiness", subtitle= "Happiness Score on 0-100 scale from Spotify data", x="Happiness Score", y="Weeks at Number One")+
  theme_minimal()
  
#PLOT 4 
counts <- billboard %>%
  group_by(year)%>%
  summarise(numsongs=n())
above10 <- billboard %>%
  filter(weeks_at_number_one>9) %>%
  group_by(year) %>%
  summarise(above10 = n())
p4 <- ggplot(counts, aes(x=year, y=numsongs))+
  geom_line()+
  geom_line(data=above10, aes(x=year, y=above10), color="purple2")+
  labs(title="Number of Songs to Top the Billboard Hot 100 List by Year", x="Year", y="Number of Songs")+
  annotate("text", x = 2020, y = 3, label = "Number of songs at #1 for 10+ weeks", color = "purple2", size = 2.5)+
  theme_minimal()
  
#PLOT 5
p5 <- ggplot(billboard)+
  geom_point(aes(x=overall_rating, y=weeks_at_number_one), alpha=.2, color="navy")+
  geom_smooth(aes(x = overall_rating, y = weeks_at_number_one), method = "loess", se = TRUE, color = "lightblue4")+
  labs(title="Weeks at Number One by Overall Song Rating", subtitle="Song rating is based on the average of three judges' scores on a 1-10 scale", x="Overall Rating (Based on average of 3 scores)", y="Weeks at Number One")+
  theme_minimal()

print(p1)
print(p2)
print(p3)
print(p4)
print(p5)
```

## Part 3
```{r Part 3}
set.seed(123)
sample_split <- initial_split(billboard, prop = 0.8)
train_data   <- training(sample_split)
test_data    <- testing(sample_split)

#MODEL 1- LINEAR (ALL VARS)
set.seed(123)
model1 <- train(weeks_at_number_one ~ year + length_sec + bpm + overall_rating + happiness, 
              data = train_data,
             method="lm",
             na.action = na.omit,
             trControl = trainControl(method = "cv", number = 5))
summary(model1)

#MODEL 2 - SMALL LINEAR
set.seed(123)
model2 <- train(weeks_at_number_one ~ bpm + overall_rating + length_sec,
                  data = train_data,
                  method = "lm",
                  trControl = trainControl(method = "cv", number = 5))
summary(model2)

#MODEL 3- TREE
set.seed(123)
model3 <- train(weeks_at_number_one ~ year + length_sec + bpm + overall_rating + happiness ,
                data = train_data,
                method="rpart", 
                trControl = trainControl(method = "cv", number = 5),
                na.action = na.omit)
print(model3)

#MODEL 4 - RF
set.seed(123)
model4 <- train(weeks_at_number_one ~ year + length_sec + bpm + overall_rating + happiness , 
                data=train_data,
                method="rf",
                trControl=trainControl(method = "cv", number = 5),
                tuneGrid=expand.grid(mtry=1:5),
                importance=TRUE,
                na.action = na.omit)
print(model4)

#MODEL 5 - KNN
set.seed(123)
model5 <- train(weeks_at_number_one ~ year + length_sec + bpm + overall_rating + happiness,
                data = train_data,
                method = "knn",
                trControl = trainControl(method = "cv", number = 5),
                tuneGrid=expand.grid(k=5:10),
                na.action = na.omit)
summary(model5)
```
Model Rationales:

- Model 1 (Linear with all variables): This model is included as a simple way to capture the all the variables and see how they will impact the response in a linear fashion. 

- Model 2 (Linear with overall rating, song length, and bpm): This model was chosen to focus on three of the variables that logically seem like they could have the biggest impact on the response based on my models. Using less variables can sometimes reduce overfitting and errors, so it is useful to test.

- Model 3 (Regression tree): I chose this model to test the non-linear relationships and interactions between the variables that the simple linear models may not capture.

- Model 4 (Random forest): This model builds on the tree model and can reduce overfitting by combining the decision tree predictions. 

- Model 5 (KNN): This model makes predictions based on similarity of the observations between songs. It looks at similarities of songs across all the variables to detect patterns.  

## Part 4
```{r Part 4}
test_data <- test_data %>%
  mutate(pred.model1=predict(model1, test_data),
         pred.model2=predict(model2, test_data),
         pred.model3=predict(model3, test_data),
         pred.model4=predict(model4, test_data),
         pred.model5=predict(model5, test_data))
test_data <- test_data %>%
  select(weeks_at_number_one, pred.model1, pred.model2, pred.model3, pred.model4, pred.model5)
glimpse(test_data)

models <- resamples(list(linear_all = model1,
                         linear_small = model2,
                         tree = model3,
                         rf = model4,
                         knn = model5))
summary(models)
metrics <- models$values

metrics <- metrics %>%
  select(contains("RMSE"), contains("MAE"))
metrics_long <- metrics %>%
  pivot_longer(
    cols = everything(),
    names_to = c("model", "metric"),
    names_sep = "~",
    values_to = "value")

p6 <- ggplot(metrics_long, aes(x = value, y = model)) +
  geom_boxplot(fill = "lightblue2") +
  facet_wrap(~metric, scales = "free_x") +
  labs(title = "Model Comparison Across RMSE and MAE", x = "Error Value", y = "Model") +
  theme_minimal() 
print(p6)
```


When comparing the results given by the models dataframe, as well as looking visually at MAE and RMSE, there are a few models that stand out. I believe the best model to go with is the Random Forest model (model 4). Model 4 has the lowest MAE (2.64), meaning it has the smallest average error. It also has  It is also on the lower end of RMSE (3.479). Although the linear models have slightly lower RMSE (3.455 and 3.471), they are very close. Additionally, all the models are pretty close in Rsquared values, so even though it is not the highest, the amount of variance explained by model 4 is comparable to the other models (and is a lot higher than the KNN model).  

Implications of predictions: The rsquared values are low for every model, meaning that it is hard for models to predict the number of weeks a song will spend at number one based on these predictors. This likely implies that the response variable is highly variable and is difficult to predict. This makes sense because sometimes the qualities that make songs popular (and likely to stay at number one) are not able to be captured. However, the random forest model is the most accurate. When looking at the test dataset and comparing the actual number of weeks to the predictions, although not super accurate, the random forest model is sometimes one of the closest predictions. 

## Files
```{r Files}
PlotsDash <- p1 + p3  / p4 + p2 + p5 
ggsave(filename="PlotsDash.png", plot=PlotsDash,
       dpi=600, width=15, height=10)
ggsave(filename="p1.png", plot=p1,
       dpi=600, width=15, height=10)
ggsave(filename="p2.png", plot=p2,
       dpi=600, width=15, height=10)
ggsave(filename="p3.png", plot=p3,
       dpi=600, width=15, height=10)
ggsave(filename="p4.png", plot=p4,
       dpi=600, width=15, height=10)
ggsave(filename="p5.png", plot=p5,
       dpi=600, width=15, height=10)
ggsave(filename="p6.png", plot=p6,
       dpi=600, width=15, height=10)
```
